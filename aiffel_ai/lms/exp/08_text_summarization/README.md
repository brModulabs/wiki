# 목차
- [텍스트 요약](#텍스트-요약)
- [훈련시키는 법](#훈련시키는-법)
- [데이터 준비](#데이터-준비)
- 데이터 전처리
- 모델 설계 및 훈련
- 인퍼런스
- 테스트 및 요약
- 프로젝트
# 텍스트 요약
- 긴글을 짧은 요약으로 변환
- 정보 손실 발생을 최소화 하는 것이 관건
- 텍스트 요약
- 이 때 2가지 방법이 존재함
## 추출적 요약
- 원문에서 문장을 추출함
- 결과가 자연스럽지 않을 수 있음
- 전통적인 방법 중 하나
## 추상적 요약
- 새로운 문장을 생성함
- NLG와 Text Classification을 섞은 것
# 훈련시키는 법
- seq2seq를 통해 추상적 요약 기법을 만들 예정
- 시작 인코더간은 양방향 RNN으로 설정하고
- 도출된 결과는 단반향 RNN으로 설정한다.
- 이때 RNN으로 설정하기 보다 LSTM으로 설정한다!(속도에 이득)
## 시작 토큰과 종료 토큰
- 문장을 생성하는 위치와 문장 생성이 종료되늰 위치를 표시해야 한다
## 어텐션 메커니즘의 사용
- 각 요소의 Hidden layer에서 중요도가 높은 요소를 뽑아서 요소를 생성한다.
## 훈련방법 요약
1. seq2seq를 사용
2. RNN 대신 LSTM을 사용합니다(hidden + cell)
3. 디코더의 예측 시퀀스에 시작 토큰과 예측 토큰을 붙입니다.
4. 어텐션 메커니즘을 사용하여 hidden state를 효과적으로 사용합니다.
5. 계산된 벡터를 이용해서 디코더는 다음 단어를 예측합니다.
# 데이터 준비
- 아마존 리뷰 [데이터 셋](https://www.kaggle.com/snap/amazon-fine-food-reviews)
- nltk를 사용하여 불용어를 제거함